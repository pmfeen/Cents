_target_: generator.diffusion_ts.gaussian_diffusion.Diffusion_TS
name: diffusion_ts
context_reconstruction_loss_weight: 0.1
tc_loss_weight: 0
noise_dim: 256
cond_emb_dim: 16
n_layer_enc: 4
n_layer_dec: 5
d_model: 128
n_steps: 1000
sampling_timesteps: 1000
sampling_batch_size: 4096
loss_type: l1 #l2
training_objective: v
loss_weighting: snr
min_snr_gamma: 5.0
beta_schedule: cosine #linear diffusion ts paper uses linear schedule
n_heads: 4
mlp_hidden_times: 4
eta: 0.0
attn_pd: 0.0
resid_pd: 0.0
kernel_size: null
padding_size: null
use_ff: True
reg_weight: null
gradient_accumulate_every: 2
ema_decay: 0.99
ema_update_interval: 10
use_ema_sampling: False
k_bins: 20
# Reconstruction-guided sampling (Algorithms 1 & 2)
recon_guide_eta: 0.1        # gradient scale for guidance
recon_guide_gamma: 1.0      # trade-off L1 vs L2 (L1 + gamma*L2)
recon_guide_algorithm: none # none | alg1 | alg2
recon_guide_K: 3            # inner steps per t for alg2 (int or list for K[t])
# Optional: dual head for x̂_a / x̂_b (set to cond_len used in recon-guided sampling)
recon_cond_len: null        # int or null; if set, use fc_a / fc_b for first vs rest of sequence
# Context embedding dropout (training only) for more robust recon-guided sampling
context_embed_dropout: 0  # 0 = disabled